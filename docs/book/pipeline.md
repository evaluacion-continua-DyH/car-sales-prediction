# Pipeline de Preprocesamiento

El pipeline de preprocesamiento se encarga de transformar el dataset original en un formato adecuado para ser utilizado por el modelo de Machine Learning.  
Todo el proceso se ejecuta en el notebook `preprocesamiento.ipynb` y garantiza que los datos est茅n limpios, consistentes y preparados para el modelado.

---

## 1. Carga y Exploraci贸n Inicial

En esta fase se realizan las primeras inspecciones del dataset:

- Carga del archivo desde la carpeta `data/`
- Revisi贸n de la estructura del dataframe (`info()`)
- Identificaci贸n de valores faltantes
- Detecci贸n de duplicados
- An谩lisis de los tipos de datos

El objetivo es comprender el estado del dataset antes de aplicar transformaciones.

---

## 2. Tratamiento de Valores Faltantes

Se emplean diferentes estrategias seg煤n el tipo de variable:

###  Variables num茅ricas  
Se imputan utilizando la **mediana**, ya que es robusta frente a valores at铆picos.  
Ejemplo:  
- `Engine HP`

###  Variables categ贸ricas  
Se imputan con la **moda**, manteniendo las categor铆as m谩s frecuentes.  
Ejemplo:  
- `Number of Doors`

Estas t茅cnicas evitan la eliminaci贸n de filas completas y mantienen la estructura del dataset.

---

## 3. Eliminaci贸n de Duplicados

Para evitar sesgos durante el entrenamiento del modelo, se eliminan todas las filas duplicadas:

```python
df = df.drop_duplicates().reset_index(drop=True)
```

## 4. Normalizaci贸n de nombre de Columnas
```python
df.columns = df.columns.str.strip().str.lower().str.replace(" ", "_")
```
## 5. Escalado de Variables Num茅ricas

## 6. Codificaci贸n de Variables Categ贸ricas
```python
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)
```

```mermaid
flowchart TD

A[Dataset Original] --> B[Inspecci贸n Inicial]
B --> C[Imputaci贸n de Valores Faltantes]
C --> D[Eliminaci贸n de Duplicados]
D --> E[Limpieza de Nombres de Columnas]
E --> F[Escalado de Variables Num茅ricas]
F --> G[One-Hot Encoding]
G --> H[Dataset Procesado]
```
