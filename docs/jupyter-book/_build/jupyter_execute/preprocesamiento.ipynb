{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf03611",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos\n",
    "\n",
    "En este notebook se lleva a cabo el proceso de preprocesamiento del dataset **Car Sales**, que servirá como entrada para el modelo de Machine Learning utilizado en el proyecto.  \n",
    "El objetivo principal es dejar los datos en un formato limpio, coherente y totalmente utilizable para la fase de modelado.\n",
    "\n",
    "Este preprocesamiento incluye:\n",
    "\n",
    "- Inspección inicial del dataset  \n",
    "- Tratamiento de valores faltantes  \n",
    "- Normalización y estandarización de variables numéricas  \n",
    "- Codificación de variables categóricas  \n",
    "- Eliminación de duplicados  \n",
    "- Guardado del dataset procesado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa978612",
   "metadata": {},
   "source": [
    "## 1. Carga del Dataset\n",
    "\n",
    "Comenzamos importando las librerías necesarias y cargando el dataset original almacenado en la carpeta `/data`.  \n",
    "Se realiza también una inspección básica para entender los tipos de datos y el número de valores faltantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subir dos niveles desde notebooks/ hasta la raíz del repo\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# Ruta al dataset original\n",
    "data_path = os.path.join(repo_root, \"data\", \"car_sales_dataset.csv\")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c085ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2eef6",
   "metadata": {},
   "source": [
    "## 2. Tratamiento de Valores Faltantes\n",
    "\n",
    "Se revisan las columnas que contienen valores nulos y se aplican diferentes técnicas de imputación:\n",
    "\n",
    "- Para variables numéricas: **mediana**\n",
    "- Para variables categóricas: **moda**\n",
    "\n",
    "Estas estrategias permiten mantener la distribución de los datos sin introducir sesgos significativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputaciones numéricas y categóricas\n",
    "df = df.copy()\n",
    "\n",
    "engine_median = df[\"Engine HP\"].median()\n",
    "df[\"Engine HP\"] = df[\"Engine HP\"].fillna(engine_median)\n",
    "\n",
    "doors_mode = df[\"Number of Doors\"].mode()[0]\n",
    "df[\"Number of Doors\"] = df[\"Number of Doors\"].fillna(doors_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48267208",
   "metadata": {},
   "source": [
    "## 3. Eliminación de Duplicados\n",
    "\n",
    "Para garantizar la calidad del dataset, se eliminan todas las filas duplicadas.  \n",
    "Esto ayuda a evitar que el modelo aprenda patrones erróneos debido a repeticiones en los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75544aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c1406",
   "metadata": {},
   "source": [
    "## 4. Limpieza y Normalización de Nombres de Columnas\n",
    "\n",
    "Con el objetivo de mantener un estilo de nombres consistente y compatible con librerías de Machine Learning, se:\n",
    "\n",
    "- eliminan espacios\n",
    "- convierten los nombres a minúsculas\n",
    "- sustituyen espacios por guiones bajos\n",
    "\n",
    "Esto facilita el manejo posterior del dataset en el pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aced41c",
   "metadata": {},
   "source": [
    "## 5. Normalización de Variables Numéricas\n",
    "\n",
    "Para las variables numéricas se aplica `StandardScaler`, que transforma cada variable para que tenga:\n",
    "\n",
    "- media = 0  \n",
    "- desviación estándar = 1  \n",
    "\n",
    "Esto es especialmente útil para modelos basados en distancia o gradiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe133fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5a948",
   "metadata": {},
   "source": [
    "## 6. Codificación de Variables Categóricas\n",
    "\n",
    "Las variables categóricas se convierten en variables numéricas mediante **One-Hot Encoding**.  \n",
    "Esta técnica crea nuevas columnas binarizadas, permitiendo al modelo interpretar correctamente los valores categóricos.\n",
    "\n",
    "Se utiliza la opción `drop_first=True` para evitar multicolinealidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957eed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22548828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = os.path.join(repo_root, \"data\", \"processed\")\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(processed_dir, \"car_sales_processed.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
